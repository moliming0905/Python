<pre>
	Author:Phize
	Version:1.0
	Name:爬虫学习过程记录
	Time:9/21/2017 5:07:52 PM 
</pre>
<font color=blue size=3>爬虫分类和使用场景</font><br/>
<pre>
	1.通用爬虫：搜索引擎用的爬虫系统
		（1）目标：尽可能把互联网上所有的网页下载下来，放到本地服务器里形成备份，再对这些网页做相关处理(提取关键字、去掉广告),最后提供一个用户搜索索引
		（2）流程：
			a):首先选取一部分已有的URL,把这些URL放到待爬取队列。
			b):从队列里取出这些URL，然后解析DNS得到主机IP,然后去这个IP对应的服务器，之后把这个爬过的URL放入已爬取队列。
			c):分析这些网页内容，找出网页里其他URL连接，继续执行第二步,直到终止。
		（3）搜索引擎如何获取一个新网站的URL:
			a)主动向搜索引擎提交网址
			b)在其他网站里设置网站的外链。
			c)搜索引擎会和DNS服务商进行合作，可以快速收录新的网站。
		（4）通用爬虫并不是万物皆可爬取的，它也需要遵守规则：
			Robots协议：协议会指明通用爬虫可以爬取网页的权限
			Robots.txt 只是一个建议，并不是所有爬虫都遵守，一般只有大型的搜索引擎爬虫需要遵守。
			个人写的小爬虫就算了^_^
		(5)通用爬虫工作流程：爬取网页——>存储数据——>内容处理——>提供检索/排名服务。
		(6)搜索引擎排名：
			PageRank值：根据网站的流量(点击量、浏览量、人气)统计，流量越高，网站越贵。
			竞价排名：谁给钱多，谁排名就高。
	    通用爬虫的缺点
			只能提供和文本相关的内容，不能提供多媒体文件和二进制文件
			提供的结果千篇一律，不能针对不同背景领域的人提供不同的搜索结果。
			不能理解人类语义上的检索。	
	  2.聚焦爬虫：爬虫程序员写的针对某种内容的爬虫
		面向主题爬虫、面向需求爬虫，会针对某种特定的内容去爬取信息。而且会保证内容信息和需求尽可能相关。
</pre><br/>

